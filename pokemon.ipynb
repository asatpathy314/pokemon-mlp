{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images(folder_name):\n",
    "    images = []\n",
    "    filenames =[]\n",
    "    for filename in os.listdir(folder_name):\n",
    "        try:\n",
    "            filepath = os.path.join(folder_name, filename)\n",
    "            img = Image.open(filepath)\n",
    "            filenames.append(filename)\n",
    "            images.append(img)\n",
    "        except Exception as error:\n",
    "            print(f\"Error loading {folder_name}: {error}\")\n",
    "    return images, filenames ###Returns images and pokemon names \n",
    "\n",
    "def image_processing(images):\n",
    "    new_images = []\n",
    "    for image in images:\n",
    "        array_image = np.asarray(image).flatten()\n",
    "        new_images.append(array_image)\n",
    "    return new_images\n",
    "\n",
    "image_Data = \"images\"\n",
    "pokemon_Data = pd.read_csv(\"pokemon.csv\")\n",
    "pokemon_images, pokemon_names = load_images(image_Data)\n",
    "data = image_processing(pokemon_images)\n",
    "\n",
    "for pokemon in pokemon_Data['Name']:\n",
    "    \n",
    "\n",
    "\n",
    "pokemon_Data['Image Data'] = data ###Add array of Pokemon data to Image data sec\n",
    "pokemon_Data = pokemon_Data.dropna(subset = ['Image Data']) ###Drop rows w/ N/A\n",
    "\n",
    "print(pokemon_Data[['Name','Type1','Type2','Evolution']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sin, pi\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arange, vstack, argmax, asarray\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normal, random\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from math import sin, pi\n",
    "from numpy import arange, vstack, argmax, asarray\n",
    "from numpy.random import normal, random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings, simplefilter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# target function to optimize\n",
    "def target_function(x, noise_level=0.1):\n",
    "    noise = normal(loc=0, scale=noise_level)\n",
    "    return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# approximation of the target function using a model\n",
    "def model_prediction(model, inputs):\n",
    "    # suppress warnings during prediction\n",
    "    with catch_warnings():\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(inputs, return_std=True)\n",
    "\n",
    "# probability of improvement acquisition function\n",
    "def prob_of_improvement(X_known, X_candidates, model):\n",
    "    # find the best predicted value so far\n",
    "    predictions, _ = model_prediction(model, X_known)\n",
    "    best_score = max(predictions)\n",
    "    # compute mean and standard deviation for candidates\n",
    "    means, std_devs = model_prediction(model, X_candidates)\n",
    "    means = means[:, 0]\n",
    "    # calculate probability of improvement\n",
    "    probabilities = norm.cdf((means - best_score) / (std_devs + 1E-9))\n",
    "    return probabilities\n",
    "\n",
    "# optimization of acquisition function to select next sample point\n",
    "def optimize_acquisition(X_known, y_known, model):\n",
    "    # generate random candidate points\n",
    "    candidate_points = random(100).reshape(-1, 1)\n",
    "    # evaluate acquisition scores for candidates\n",
    "    scores = prob_of_improvement(X_known, candidate_points, model)\n",
    "    # find the candidate with the highest score\n",
    "    best_idx = argmax(scores)\n",
    "    return candidate_points[best_idx, 0]\n",
    "\n",
    "# visualize the true observations and the surrogate model's predictions\n",
    "def visualize(X_known, y_known, model):\n",
    "    # scatter plot of observed data points\n",
    "    plt.scatter(X_known, y_known)\n",
    "    # line plot of surrogate model predictions over domain\n",
    "    domain_samples = asarray(arange(0, 1, 0.001)).reshape(-1, 1)\n",
    "    predictions, _ = model_prediction(model, domain_samples)\n",
    "    plt.plot(domain_samples, predictions)\n",
    "    plt.show()\n",
    "\n",
    "# generate initial noisy samples from the domain\n",
    "X_data = random(100).reshape(-1, 1)\n",
    "y_data = asarray([target_function(x) for x in X_data]).reshape(-1, 1)\n",
    "\n",
    "# initialize Gaussian Process model\n",
    "gp_model = GaussianProcessRegressor()\n",
    "gp_model.fit(X_data, y_data)\n",
    "\n",
    "# visualize initial state of observations and surrogate model\n",
    "visualize(X_data, y_data, gp_model)\n",
    "\n",
    "# perform iterative optimization process\n",
    "for iteration in range(100):\n",
    "    # determine the next sampling point using acquisition function optimization\n",
    "    next_sample = optimize_acquisition(X_data, y_data, gp_model)\n",
    "    \n",
    "    # evaluate the target function at the selected point\n",
    "    observed_value = target_function(next_sample)\n",
    "    \n",
    "    # print progress information\n",
    "    predicted_value, _ = model_prediction(gp_model, [[next_sample]])\n",
    "    print(f'>x={next_sample:.3f}, predicted={predicted_value[0]:.6f}, actual={observed_value:.3f}')\n",
    "    \n",
    "    # update dataset with new sample and retrain the model\n",
    "    X_data = vstack((X_data, [[next_sample]]))\n",
    "    y_data = vstack((y_data, [[observed_value]]))\n",
    "    \n",
    "    gp_model.fit(X_data, y_data)\n",
    "\n",
    "# visualize final state of observations and surrogate model predictions\n",
    "visualize(X_data, y_data, gp_model)\n",
    "\n",
    "# report the best result found during optimization\n",
    "best_idx = argmax(y_data)\n",
    "print(f'Best Result: x={X_data[best_idx][0]:.3f}, y={y_data[best_idx][0]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
